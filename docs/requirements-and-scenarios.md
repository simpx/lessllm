# LessLLM éœ€æ±‚åˆ†æä¸ä½¿ç”¨åœºæ™¯

## é¡¹ç›®å®šä½

LessLLM æ˜¯ä¸€ä¸ªè½»é‡çº§çš„ LLM API ä»£ç†æ¡†æ¶ï¼Œä¸“æ³¨äºè§£å†³ **ç½‘ç»œè¿é€šæ€§** å’Œ **APIä½¿ç”¨åˆ†æ** ä¸¤å¤§æ ¸å¿ƒç—›ç‚¹ã€‚é¡¹ç›®ç§‰æ‰¿ "doing more with less code/gpu/mem" çš„ç†å¿µï¼Œä¸ºå¼€å‘è€…æä¾›ç®€å•é«˜æ•ˆçš„ LLM ä½¿ç”¨ä½“éªŒã€‚

## æ ¸å¿ƒéœ€æ±‚

### 1. ç½‘ç»œè¿é€šæ€§é—®é¢˜ ğŸŒ

**ç—›ç‚¹**: åœ¨å—é™ç½‘ç»œç¯å¢ƒä¸‹æ— æ³•ç›´æ¥è®¿é—® LLM API æœåŠ¡

**éœ€æ±‚ç»†èŠ‚**:
- æ”¯æŒ HTTP/HTTPS ä»£ç†
- æ”¯æŒ SOCKS4/5 ä»£ç†  
- ä»£ç†è®¤è¯æ”¯æŒï¼ˆç”¨æˆ·åå¯†ç ï¼‰
- è¿æ¥æ± ç®¡ç†å’Œè¶…æ—¶æ§åˆ¶
- ä»£ç†å¤±è´¥æ—¶çš„é”™è¯¯æç¤ºå’Œå›é€€æœºåˆ¶

**ç›®æ ‡ç”¨æˆ·**: 
- ä¼ä¸šç¯å¢ƒå¼€å‘è€…
- ç½‘ç»œå—é™åœ°åŒºçš„ç”¨æˆ·
- éœ€è¦é€šè¿‡ä»£ç†è®¿é—®å¤–éƒ¨æœåŠ¡çš„å›¢é˜Ÿ

### 2. APIä½¿ç”¨åˆ†æéœ€æ±‚ ğŸ“Š

**ç—›ç‚¹**: ç¼ºä¹å¯¹ LLM API ä½¿ç”¨æƒ…å†µçš„æ·±åº¦æ´å¯Ÿï¼Œéš¾ä»¥ä¼˜åŒ–æˆæœ¬å’Œæ€§èƒ½

**éœ€æ±‚ç»†èŠ‚**:

#### å®Œæ•´çš„è°ƒç”¨è®°å½•
- è®°å½•å®Œæ•´çš„è¯·æ±‚/å“åº”æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
- æ”¯æŒ OpenAI å’Œ Claude API æ ¼å¼
- è¯·æ±‚å…ƒæ•°æ®ï¼šæ—¶é—´æˆ³ã€æ¨¡å‹ã€ç”¨æˆ·IDç­‰
- å“åº”æ•°æ®ï¼štokenä½¿ç”¨é‡ã€æˆæœ¬ã€é”™è¯¯ä¿¡æ¯ç­‰

#### æ€§èƒ½æŒ‡æ ‡æ”¶é›†
- **TTFT (Time To First Token)**: å“åº”å®æ—¶æ€§æŒ‡æ ‡
- **TPOT (Time Per Output Token)**: ç”Ÿæˆé€Ÿåº¦æŒ‡æ ‡  
- **æ€»å»¶è¿Ÿ**: ç«¯åˆ°ç«¯å“åº”æ—¶é—´
- **æµå¼ vs éæµå¼**: ä¸åŒæ¨¡å¼çš„æ€§èƒ½å¯¹æ¯”
- **ç½‘ç»œå»¶è¿Ÿåˆ†è§£**: åŒºåˆ†ç½‘ç»œå’Œè®¡ç®—æ—¶é—´

#### æ™ºèƒ½ç¼“å­˜åˆ†æ
- **é¢„ä¼°ç¼“å­˜å‘½ä¸­**: åŸºäº prompt å†…å®¹é¢„æµ‹ç¼“å­˜æ•ˆæœ
- **å®é™…ç¼“å­˜å¯¹æ¯”**: ä¸ API è¿”å›çš„çœŸå®ç¼“å­˜æ•°æ®å¯¹æ¯”
- **ç¼“å­˜ä¼˜åŒ–å»ºè®®**: è¯†åˆ«å¯ä¼˜åŒ–çš„ prompt æ¨¡å¼
- **æˆæœ¬å½±å“åˆ†æ**: ç¼“å­˜å¯¹æˆæœ¬çš„å½±å“é‡åŒ–

### 3. æ•°æ®æŒä¹…åŒ–éœ€æ±‚ ğŸ’¾

**ç—›ç‚¹**: éœ€è¦çµæ´»çš„æ•°æ®å­˜å‚¨æ–¹æ¡ˆï¼Œä¾¿äºåç»­åˆ†æ

**éœ€æ±‚ç»†èŠ‚**:
- æœ¬åœ°åŒ–å­˜å‚¨ï¼ˆæ— éœ€é¢å¤–åŸºç¡€è®¾æ–½ï¼‰
- æ”¯æŒ SQL æŸ¥è¯¢ï¼ˆä¾¿äºå¤æ‚åˆ†æï¼‰
- æ•°æ®å¯¼å‡ºåŠŸèƒ½ï¼ˆParquet æ ¼å¼ï¼Œpandas å‹å¥½ï¼‰
- è½»é‡çº§æ•°æ®åº“ï¼ˆDuckDBï¼‰
- ä¿æŒ lessllm ç®€å•ï¼Œè®©ç”¨æˆ·åœ¨å¤–éƒ¨ç³»ç»Ÿåšæ·±åº¦åˆ†æ

## ä¸»è¦ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: AIå·¥å…·å¼€å‘å›¢é˜Ÿ

**èƒŒæ™¯**: æŸ AI å·¥å…·å¼€å‘å›¢é˜Ÿéœ€è¦åœ¨ä¸åŒ LLM é—´åˆ‡æ¢ä»¥æ‰¾åˆ°æœ€é€‚åˆçš„æ¨¡å‹

**å…·ä½“ç—›ç‚¹**:
- æ¯ä¸ªæ¨¡å‹ API æ ¼å¼ä¸åŒï¼Œåˆ‡æ¢æˆæœ¬é«˜
- æ— æ³•ç»Ÿä¸€ç›‘æ§æ‰€æœ‰æ¨¡å‹çš„ä½¿ç”¨æƒ…å†µ  
- æµ‹è¯•æ—¶éœ€è¦é¢‘ç¹ä¿®æ”¹ä»£ç 
- ç½‘ç»œç¯å¢ƒå¯èƒ½æ— æ³•ç›´æ¥è®¿é—®æŸäº› API

**lessllm è§£å†³æ–¹æ¡ˆ**:
```python
# å¼€å‘è€…åªéœ€è¦ä¿®æ”¹é…ç½®ï¼Œæ— éœ€æ”¹ä»£ç 
# é…ç½®æ–‡ä»¶ lessllm.yaml
proxy:
  socks_proxy: "socks5://127.0.0.1:1080" 
  
models:
  "gpt-4": 
    provider: "openai"
    model: "gpt-4-0613"
  "claude": 
    provider: "anthropic" 
    model: "claude-3-opus-20240229"

# åº”ç”¨ä»£ç ä¿æŒä¸å˜
client = openai.OpenAI(base_url="http://localhost:8000/v1")
response = client.chat.completions.create(
    model="claude",  # å®é™…ä¼šè·¯ç”±åˆ°Claude API
    messages=[{"role": "user", "content": "Hello"}]
)
```

**ä»·å€¼ä½“ç°**:
- ç»Ÿä¸€æ¥å£ï¼Œæ— éœ€ä¿®æ”¹ä¸šåŠ¡ä»£ç 
- å®Œæ•´çš„ä½¿ç”¨æ•°æ®è®°å½•ï¼Œä¾¿äºæ¨¡å‹é€‰æ‹©å†³ç­–
- è§£å†³ç½‘ç»œè¿é€šæ€§é—®é¢˜

### åœºæ™¯2: ä¼ä¸šå†…éƒ¨AIåº”ç”¨

**èƒŒæ™¯**: å¤§å‹ä¼ä¸šå†…éƒ¨å¤šä¸ªéƒ¨é—¨éƒ½åœ¨ä½¿ç”¨ LLMï¼Œéœ€è¦ç»Ÿä¸€ç®¡ç†å’Œç›‘æ§

**å…·ä½“ç—›ç‚¹**:
- å„éƒ¨é—¨ä½¿ç”¨ä¸åŒæ¨¡å‹ï¼Œæˆæœ¬éš¾ä»¥æ§åˆ¶
- æ— æ³•ç›‘æ§æ•æ„Ÿæ•°æ®æ˜¯å¦æ³„æ¼
- ç½‘ç»œå®‰å…¨è¦æ±‚ï¼Œéœ€è¦é€šè¿‡ä»£ç†è®¿é—®å¤–éƒ¨ API
- ç¼ºä¹ä½¿ç”¨æ•ˆç‡åˆ†æ

**lessllm è§£å†³æ–¹æ¡ˆ**:
```python
# ä¼ä¸šçº§ä½¿ç”¨
import lessllm

# é…ç½®ä»£ç†å’Œæ—¥å¿—
lessllm.configure({
    "proxy": {
        "http_proxy": "http://proxy.company.com:8080",
        "auth": {
            "username": "${PROXY_USER}",
            "password": "${PROXY_PASS}"
        }
    },
    "logging": {
        "enabled": True,
        "storage": "duckdb",
        "db_path": "/shared/ai_usage_logs.db"
    }
})

# æ­£å¸¸ä½¿ç”¨ï¼Œè‡ªåŠ¨è®°å½•æ‰€æœ‰è°ƒç”¨
client = openai.OpenAI(base_url="http://localhost:8000/v1")
response = client.chat.completions.create(...)

# ç®¡ç†å‘˜åˆ†æä½¿ç”¨æƒ…å†µ
usage_report = lessllm.query("""
    SELECT 
        model,
        COUNT(*) as calls,
        SUM(estimated_cost_usd) as total_cost,
        AVG(estimated_cache_hit_rate) as avg_cache_hit_rate
    FROM api_calls 
    WHERE timestamp >= '2024-01-01'
    GROUP BY model
""")
```

**ä»·å€¼ä½“ç°**:
- è§£å†³ä¼ä¸šç½‘ç»œç¯å¢ƒçš„è¿é€šæ€§é—®é¢˜
- æä¾›è¯¦ç»†çš„ä½¿ç”¨é‡å’Œæˆæœ¬åˆ†æ
- æ”¯æŒé›†ä¸­åŒ–çš„ä½¿ç”¨ç›‘æ§å’Œç®¡ç†

### åœºæ™¯3: AIç ”ç©¶å’Œæ¨¡å‹æ¯”è¾ƒ

**èƒŒæ™¯**: ç ”ç©¶äººå‘˜éœ€è¦æ¯”è¾ƒä¸åŒæ¨¡å‹åœ¨ç›¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°

**å…·ä½“ç—›ç‚¹**:
- éœ€è¦åŒæ—¶è°ƒç”¨å¤šä¸ªæ¨¡å‹ API
- ç»“æœæ ¼å¼ä¸ç»Ÿä¸€ï¼Œéš¾ä»¥æ¯”è¾ƒ
- æ— æ³•æ–¹ä¾¿åœ°è®°å½•å®éªŒæ•°æ®
- ç¼ºä¹æ€§èƒ½å’Œæ•ˆç‡çš„é‡åŒ–æŒ‡æ ‡

**lessllm è§£å†³æ–¹æ¡ˆ**:
```python
# ç ”ç©¶å®éªŒè®¾ç½®
models_to_test = ["gpt-4", "claude-3-opus", "gemini-pro"]
test_prompts = [...]

results = []
for model in models_to_test:
    for prompt in test_prompts:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            # lessllmè‡ªåŠ¨è®°å½•æ‰€æœ‰è¯·æ±‚è¯¦æƒ…
        )
        results.append({
            "model": model,
            "prompt": prompt,
            "response": response.choices[0].message.content
        })

# è‡ªåŠ¨ç”Ÿæˆå®éªŒæŠ¥å‘Š
experiment_data = lessllm.query("""
    SELECT 
        model,
        AVG(estimated_ttft_ms) as avg_ttft,
        AVG(estimated_tpot_ms) as avg_tpot,
        AVG(estimated_cache_hit_rate) as avg_cache_hit,
        AVG(estimated_cost_usd) as avg_cost
    FROM api_calls 
    WHERE timestamp >= '2024-01-01'
    GROUP BY model
""")

# å¯¼å‡ºè¯¦ç»†æ•°æ®ç”¨äºè¿›ä¸€æ­¥åˆ†æ
lessllm.export_logs("experiment_results.parquet")
```

**ä»·å€¼ä½“ç°**:
- ç»Ÿä¸€çš„APIæ¥å£ï¼Œä¾¿äºæ‰¹é‡æµ‹è¯•
- è‡ªåŠ¨æ”¶é›†æ€§èƒ½å’Œæˆæœ¬æ•°æ®
- ç»“æ„åŒ–çš„å®éªŒæ•°æ®è®°å½•

### åœºæ™¯4: å¼€å‘è°ƒè¯•å’Œæ€§èƒ½ä¼˜åŒ–

**èƒŒæ™¯**: å¼€å‘è€…åœ¨è°ƒè¯• LLM åº”ç”¨æ—¶éœ€è¦è¯¦ç»†çš„è¯·æ±‚ä¿¡æ¯

**å…·ä½“ç—›ç‚¹**:
- éš¾ä»¥å¤ç°ç‰¹å®šçš„ API è°ƒç”¨é—®é¢˜
- ä¸çŸ¥é“å“ªäº› prompt å¯¼è‡´äº†é«˜æˆæœ¬
- æ— æ³•åˆ†æå“åº”æ—¶é—´ç“¶é¢ˆ
- ç¼ºä¹ç¼“å­˜ä¼˜åŒ–çš„é‡åŒ–æŒ‡æ ‡

**lessllm è§£å†³æ–¹æ¡ˆ**:
```python
# å¼€å¯è¯¦ç»†è°ƒè¯•æ¨¡å¼
lessllm.config.debug_mode = True
lessllm.config.enable_cache_analysis = True

# æ‰€æœ‰è¯·æ±‚éƒ½ä¼šè¢«è¯¦ç»†è®°å½•
response = client.chat.completions.create(
    model="gpt-4",
    messages=[...],
    # lessllmè‡ªåŠ¨è®°å½•:
    # - å®Œæ•´çš„è¯·æ±‚/å“åº”
    # - æ€§èƒ½æŒ‡æ ‡(TTFT/TPOT)
    # - ç¼“å­˜åˆ†æ
    # - ç½‘ç»œå»¶è¿Ÿåˆ†è§£
)

# æ€§èƒ½åˆ†ææŸ¥è¯¢
performance_issues = lessllm.query("""
    SELECT 
        request_id,
        model,
        estimated_ttft_ms,
        estimated_tpot_ms,
        estimated_cache_hit_rate,
        actual_cache_hit_rate
    FROM api_calls 
    WHERE estimated_ttft_ms > 5000  -- æ‰¾å‡ºå“åº”æ…¢çš„è¯·æ±‚
    ORDER BY timestamp DESC
""")

# ç¼“å­˜ä¼˜åŒ–åˆ†æ
cache_optimization = lessllm.query("""
    SELECT 
        model,
        AVG(estimated_cache_hit_rate) as predicted_hit_rate,
        AVG(actual_cache_hit_rate) as actual_hit_rate,
        (AVG(actual_cache_hit_rate) - AVG(estimated_cache_hit_rate)) as hit_rate_diff
    FROM api_calls 
    WHERE actual_cache_hit_rate IS NOT NULL
    GROUP BY model
""")
```

**ä»·å€¼ä½“ç°**:
- å®Œæ•´çš„è°ƒè¯•ä¿¡æ¯è®°å½•
- æ€§èƒ½ç“¶é¢ˆè¯†åˆ«å’Œåˆ†æ
- ç¼“å­˜ä¼˜åŒ–çš„é‡åŒ–æŒ‡å¯¼

## å…¸å‹ç”¨æ³•æ¨¡å¼

### 1. ä½œä¸ºä»£ç†æœåŠ¡å™¨ä½¿ç”¨

```bash
# å¯åŠ¨ lessllm ä»£ç†æœåŠ¡å™¨
lessllm server --port 8000 --config lessllm.yaml

# åº”ç”¨ç¨‹åºè¿æ¥åˆ° lessllm
export OPENAI_BASE_URL="http://localhost:8000/v1"
python my_ai_app.py
```

### 2. ä½œä¸º Python åº“é›†æˆ

```python
import lessllm
import openai

# é…ç½® lessllm
lessllm.configure({
    "proxy": {"socks_proxy": "socks5://127.0.0.1:1080"},
    "logging": {"enabled": True}
})

# æ­£å¸¸ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯
client = openai.OpenAI(base_url=lessllm.get_proxy_url())
response = client.chat.completions.create(...)

# æŸ¥è¯¢ä½¿ç”¨æƒ…å†µ
stats = lessllm.get_usage_stats(days=7)
```

### 3. æ•°æ®åˆ†æå’Œå¯¼å‡º

```python
# SQL æŸ¥è¯¢åˆ†æ
results = lessllm.query("""
    SELECT model, date(timestamp) as date, 
           sum(actual_total_tokens) as daily_tokens,
           avg(estimated_cache_hit_rate) as avg_cache_hit
    FROM api_calls 
    GROUP BY model, date(timestamp)
    ORDER BY date DESC
""")

# å¯¼å‡ºåˆ° Parquet æ–‡ä»¶ç”¨äºæ·±åº¦åˆ†æ
lessllm.export_logs(
    filepath="ai_usage_analysis.parquet",
    start_date="2024-01-01",
    filters={"model": ["gpt-4", "claude-3-opus"]}
)

# åœ¨ pandas ä¸­è¿›è¡Œåˆ†æ
import pandas as pd
df = pd.read_parquet("ai_usage_analysis.parquet")
```

## æ ¸å¿ƒè®¾è®¡åŸåˆ™

### 1. ç®€å•æ€§ä¼˜å…ˆ
- æœ€å°åŒ–ä¾èµ–ï¼Œé¿å…å¤æ‚çš„åŸºç¡€è®¾æ–½è¦æ±‚
- å¼€ç®±å³ç”¨ï¼Œé…ç½®ç®€å•
- ä¿æŒ lessllm åŠŸèƒ½èšç„¦ï¼Œå¤æ‚åˆ†æç•™ç»™å¤–éƒ¨å·¥å…·

### 2. æ•°æ®å®Œæ•´æ€§
- å®Œæ•´ä¿å­˜åŸå§‹ API è¯·æ±‚å’Œå“åº”
- åŒºåˆ†åŸå§‹æ•°æ®å’Œé¢„ä¼°åˆ†æ
- æ”¯æŒæ•°æ®æº¯æºå’ŒéªŒè¯

### 3. æ€§èƒ½å’Œæˆæœ¬æ„è¯†
- æä¾›æ€§èƒ½å’Œæˆæœ¬çš„é‡åŒ–æŒ‡æ ‡
- æ™ºèƒ½ç¼“å­˜åˆ†æï¼Œå¸®åŠ©ä¼˜åŒ–ä½¿ç”¨ç­–ç•¥
- æ”¯æŒä½¿ç”¨æ¨¡å¼çš„æ·±åº¦åˆ†æ

### 4. å¯æ‰©å±•æ€§
- æ”¯æŒå¤šç§ LLM æä¾›å•†
- çµæ´»çš„é…ç½®ç³»ç»Ÿ
- ä¾¿äºé›†æˆçš„ API è®¾è®¡

## é¡¹ç›®ä»·å€¼

LessLLM ä¸ä»…è§£å†³äº†ç½‘ç»œè¿é€šæ€§è¿™ä¸€åŸºç¡€é—®é¢˜ï¼Œæ›´é‡è¦çš„æ˜¯æä¾›äº† **LLM ä½¿ç”¨çš„æ€§èƒ½å’Œæˆæœ¬ä¼˜åŒ–å·¥å…·**ã€‚é€šè¿‡è¯¦ç»†çš„æ•°æ®è®°å½•å’Œæ™ºèƒ½åˆ†æï¼Œå¸®åŠ©ç”¨æˆ·ï¼š

1. **ä¼˜åŒ–æ¨¡å‹é€‰æ‹©** - åŸºäºæ€§èƒ½å’Œæˆæœ¬æ•°æ®åšå‡ºæ•°æ®é©±åŠ¨çš„å†³ç­–
2. **æ”¹è¿› prompt è®¾è®¡** - åŸºäºç¼“å­˜åˆ†æä¼˜åŒ–æç¤ºè¯ç­–ç•¥  
3. **ç›‘æ§æœåŠ¡è´¨é‡** - åŸºäºæ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿å‘ç°é—®é¢˜
4. **æ§åˆ¶ä½¿ç”¨æˆæœ¬** - é€šè¿‡ä½¿ç”¨é‡åˆ†æå’Œé¢„ç®—ç®¡ç†

è¿™ä½¿å¾— LessLLM æˆä¸º LLM åº”ç”¨å¼€å‘å’Œè¿ç»´ä¸­ä¸å¯æˆ–ç¼ºçš„å·¥å…·ã€‚